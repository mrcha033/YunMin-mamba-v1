# calculate_scan_order.py
import torch
import numpy as np
from scipy.spatial.distance import pdist, squareform
import os

def calculate_scan_order():
    print("ğŸ§  [Step 2] Correlation Scan ìˆœì—´ ê³„ì‚° ì‹œì‘...")
    
    # hidden states ë¡œë”©
    if not os.path.exists("hidden_states.pt"):
        raise FileNotFoundError("âŒ hidden_states.pt íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. extract_hidden_states.pyë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
    
    print("ğŸ“¥ Hidden states ë¡œë”©...")
    hidden_states = torch.load("hidden_states.pt")  # shape: [L, D]
    print(f"ğŸ“Š ì›ë³¸ í¬ê¸°: {hidden_states.shape}")
    
    # ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•´ í¬ê¸° ì œí•œ
    max_tokens = 512  # ë©”ëª¨ë¦¬ í•œê³„ ê³ ë ¤
    if hidden_states.shape[0] > max_tokens:
        print(f"âš¡ ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•´ {max_tokens}ê°œ í† í°ìœ¼ë¡œ ì¶•ì†Œ")
        # ê· ë“± ìƒ˜í”Œë§
        indices = np.linspace(0, hidden_states.shape[0]-1, max_tokens, dtype=int)
        hidden_states = hidden_states[indices]
    
    print(f"ğŸ¯ ìµœì¢… í¬ê¸°: {hidden_states.shape}")

    # Pearson ìƒê´€ê³„ìˆ˜ ê¸°ë°˜ ê±°ë¦¬ í–‰ë ¬ ìƒì„±
    print("ğŸ”— ìƒê´€ê³„ìˆ˜ í–‰ë ¬ ê³„ì‚° ì¤‘...")
    X = hidden_states.numpy()
    
    # ê° í† í°ì„ ì •ê·œí™” (zero mean, unit variance)
    X = (X - X.mean(axis=1, keepdims=True)) / (X.std(axis=1, keepdims=True) + 1e-8)
    
    # ìƒê´€ê³„ìˆ˜ í–‰ë ¬ ê³„ì‚°
    corr = np.corrcoef(X)  # shape: [L, L]
    
    # NaN ì²˜ë¦¬
    corr = np.nan_to_num(corr, nan=0.0)
    
    # ê±°ë¦¬ í–‰ë ¬: ë†’ì€ ìƒê´€ â†’ ì§§ì€ ê±°ë¦¬
    dist = 1 - np.abs(corr)  # ì ˆëŒ€ê°’ ì‚¬ìš©ìœ¼ë¡œ ìŒì˜ ìƒê´€ë„ ê³ ë ¤
    
    print(f"ğŸ“ ê±°ë¦¬ í–‰ë ¬ ìƒì„± ì™„ë£Œ: {dist.shape}")
    print(f"ğŸ“ˆ í‰ê·  ê±°ë¦¬: {dist.mean():.4f}, í‘œì¤€í¸ì°¨: {dist.std():.4f}")

    # Nearest Neighbor ìˆœíšŒ (TSP heuristic)
    print("ğŸš¶ Nearest Neighbor TSP ìˆœíšŒ ì‹œì‘...")
    L = dist.shape[0]
    visited = [0]  # ì²« ë²ˆì§¸ í† í°ë¶€í„° ì‹œì‘
    unvisited = set(range(1, L))

    for step in range(L - 1):
        if step % 50 == 0:
            print(f"  ì§„í–‰ë¥ : {step+1}/{L-1} ({(step+1)/(L-1)*100:.1f}%)")
            
        last = visited[-1]
        # ê°€ì¥ ê°€ê¹Œìš´(ìƒê´€ë„ ë†’ì€) ë‹¤ìŒ í† í° ì„ íƒ
        next_idx = min(unvisited, key=lambda j: dist[last][j])
        visited.append(next_idx)
        unvisited.remove(next_idx)

    pi = np.array(visited)  # ìˆœì—´
    pi_inv = np.argsort(pi)  # ì—­ìˆœì—´

    print(f"âœ… ìˆœì—´ ê³„ì‚° ì™„ë£Œ!")
    print(f"ğŸ“Š ìˆœì—´ Ï€: ê¸¸ì´ {len(pi)}, ë²”ìœ„ [{pi.min()}, {pi.max()}]")
    print(f"ğŸ“Š ì—­ìˆœì—´ Ï€â»Â¹: ê¸¸ì´ {len(pi_inv)}, ë²”ìœ„ [{pi_inv.min()}, {pi_inv.max()}]")

    # ìˆœì—´ í’ˆì§ˆ í‰ê°€
    original_total_dist = sum(dist[i, i+1] for i in range(L-1))  # ì›ë³¸ ìˆœì„œ
    optimized_total_dist = sum(dist[pi[i], pi[i+1]] for i in range(L-1))  # ìµœì í™”ëœ ìˆœì„œ
    
    improvement = (original_total_dist - optimized_total_dist) / original_total_dist * 100
    print(f"ğŸ¯ ìˆœì—´ í’ˆì§ˆ:")
    print(f"   ì›ë³¸ ì´ ê±°ë¦¬: {original_total_dist:.4f}")
    print(f"   ìµœì í™” ì´ ê±°ë¦¬: {optimized_total_dist:.4f}")
    print(f"   ê°œì„ ìœ¨: {improvement:.2f}%")

    # ì €ì¥
    np.save("scan_order.npy", pi)
    np.save("scan_order_inv.npy", pi_inv)
    
    print("ğŸ’¾ ì €ì¥ ì™„ë£Œ:")
    print(f"   ğŸ“„ scan_order.npy: {pi.shape}")
    print(f"   ğŸ“„ scan_order_inv.npy: {pi_inv.shape}")
    
    # ìˆœì—´ ë¯¸ë¦¬ë³´ê¸°
    print(f"ğŸ” ìˆœì—´ ë¯¸ë¦¬ë³´ê¸° (ì²˜ìŒ 10ê°œ): {pi[:10]}")
    print(f"ğŸ” ì—­ìˆœì—´ ë¯¸ë¦¬ë³´ê¸° (ì²˜ìŒ 10ê°œ): {pi_inv[:10]}")
    
    return {
        'permutation_length': len(pi),
        'improvement_rate': improvement,
        'total_distance_reduction': original_total_dist - optimized_total_dist
    }

if __name__ == "__main__":
    calculate_scan_order() 