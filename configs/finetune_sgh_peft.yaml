# SGH-PEFT Fine-tuning Configuration - Pillar 3: Sparsity-Guided Hybrid PEFT
# This configuration enables hybrid LoRA/IA³ adaptation guided by SDM importance scores

# Base model configuration (should match SDM pre-training)
model:
  d_model: 768
  n_layer: 12
  vocab_size: 50257
  d_state: 16
  d_conv: 4

# SGH-PEFT specific configuration
sgh_peft:
  # LoRA configuration
  lora_high_rank: 16        # High-rank LoRA for most important layers
  lora_low_rank: 4          # Low-rank LoRA for medium importance layers
  lora_alpha_factor: 2      # alpha = rank * factor (controls adaptation strength)
  lora_dropout: 0.05        # Dropout for LoRA layers
  
  # IA³ configuration
  ia3_init_std: 0.02        # Standard deviation for IA³ initialization
  
  # Importance-based allocation thresholds
  high_importance_mean_threshold: 0.5     # mean_imp > 0.5 for high-rank LoRA
  high_importance_active_threshold: 60.0  # active% > 60% for high-rank LoRA
  medium_importance_mean_threshold: 0.0   # mean_imp > 0.0 for low-rank LoRA
  medium_importance_active_threshold: 40.0 # active% > 40% for low-rank LoRA
  low_importance_mean_threshold: -0.5     # mean_imp > -0.5 for IA³
  
  # Sparsity integration
  apply_sparsity_mask: true    # Apply SDM masks to LoRA/IA³ updates
  freeze_base_model: true      # Freeze all base model parameters

# Training configuration
training:
  batch_size: 16               # Smaller batch size for fine-tuning
  learning_rate: 5e-5          # Lower learning rate for fine-tuning
  weight_decay: 0.01
  warmup_steps: 100            # Fewer warmup steps for fine-tuning
  max_steps: 2000              # Task-dependent, adjust per GLUE task
  gradient_accumulation_steps: 2
  max_grad_norm: 1.0
  early_stopping_patience: 3
  early_stopping_threshold: 0.0
  monitor_metric: "eval_accuracy"

# Task-specific configurations for GLUE benchmark
# Default experiments use the subset: [sst2, mrpc, qnli, mnli]
tasks:
  cola:      # Corpus of Linguistic Acceptability
    num_labels: 2
    metric: "matthews_correlation"
    max_steps: 1000
  
  sst2:      # Stanford Sentiment Treebank
    num_labels: 2
    metric: "accuracy"
    max_steps: 1500
  
  mrpc:      # Microsoft Research Paraphrase Corpus
    num_labels: 2
    metric: "f1"
    max_steps: 1000
  
  stsb:      # Semantic Textual Similarity Benchmark
    num_labels: 1
    metric: "pearson_correlation"
    max_steps: 1500
  
  qqp:       # Quora Question Pairs
    num_labels: 2
    metric: "f1"
    max_steps: 2000
  
  mnli:      # Multi-Genre Natural Language Inference
    num_labels: 3
    metric: "accuracy"
    max_steps: 3000
  
  qnli:      # Question Natural Language Inference
    num_labels: 2
    metric: "accuracy"
    max_steps: 2000
  
  rte:       # Recognizing Textual Entailment
    num_labels: 2
    metric: "accuracy"
    max_steps: 800
  
  wnli:      # Winograd Natural Language Inference
    num_labels: 2
    metric: "accuracy"
    max_steps: 500

# Logging configuration
logging:
  log_interval: 25            # More frequent logging for fine-tuning
  eval_interval: 200          # Evaluate every 200 steps
  save_interval: 500          # Save checkpoint every 500 steps
  wandb_project: "hardware-data-parameter-codesign"
  run_name: "sgh_peft_finetune"

# Advanced SGH-PEFT settings
advanced_sgh_peft:
  # Dynamic adaptation
  enable_dynamic_allocation: false    # Future: adjust allocation during training
  adaptation_warmup_steps: 50         # Steps before applying full adaptation
  
  # Importance score updates
  update_importance_scores: false     # Future: re-compute importance during training
  importance_update_interval: 500     # Interval for importance updates
  
  # Regularization
  adapter_l2_regularization: 0.001    # L2 regularization on adapter parameters
  sparsity_preservation_weight: 0.1   # Weight for preserving SDM sparsity
  
  # Efficiency optimizations
  use_gradient_checkpointing: true    # Save memory during training
  mixed_precision: "fp16"             # Use mixed precision training
  
  # Analysis and monitoring
  track_adapter_utilization: true     # Monitor which adapters are being used
  log_importance_drift: true          # Track how importance scores change
  save_adapter_weights_separately: true # Save adapters separately for analysis 