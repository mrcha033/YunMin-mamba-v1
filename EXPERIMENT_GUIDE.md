# YunMin Correlation Scan Experiments Guide

## ğŸ§ª Experiment Overview

This guide covers the systematic evaluation of **YunMin Correlation Scan** techniques for Mamba models across 4 different configurations:

| Mode | Description | Configuration |
|------|-------------|---------------|
| **Baseline** | Full fine-tuning | All parameters trainable |
| **LoRA-only** | PEFT @ SSM-only | LoRA on 4 SSM layers only |
| **Scan-only** | Ï€ insertion | Correlation scan permutation |
| **Hybrid** | LoRA + Scan | Combined approach |
| **IAÂ³-only** | Channel scaling | Per-channel vectors |
| **IAÂ³ + LoRA** | IAÂ³ with LoRA | Hybrid tuning |

## ğŸ“Š Metrics Tracked

Each experiment automatically tracks:

- **Perplexity** - Language modeling performance
- **Training Time** - Epoch duration and total time
- **GPU Memory** - Peak GPU usage per epoch
- **Trainable Parameters** - Count and percentage
- **W&B Logging** - Real-time monitoring

## ğŸš€ Quick Start

### 1. Quick Test (Recommended First)

Validate all modes with minimal configuration:

```bash
python quick_test.py
```

Expected output:
```
ğŸš€ YunMin Quick Test Suite
========================================
ğŸ§ª Quick test: baseline mode
âœ… baseline test passed in 45.2s
ğŸ§ª Quick test: lora mode  
âœ… lora test passed in 38.1s
ğŸ§ª Quick test: scan mode
âœ… scan test passed in 42.3s
ğŸ§ª Quick test: hybrid mode
âœ… hybrid test passed in 39.7s

ğŸ§ª Quick test: ia3 mode
âœ… ia3 test passed in 40.2s
ğŸ§ª Quick test: ia3_lora mode
âœ… ia3_lora test passed in 41.0s
ğŸ“Š Quick Test Results:
----------------------------------------
baseline     âœ… PASS
lora         âœ… PASS
scan         âœ… PASS
hybrid       âœ… PASS
ia3         âœ… PASS
ia3_lora    âœ… PASS

ğŸ¯ Overall: All tests passed!
ğŸš€ Ready for full experiments!
```

### 2. Individual Experiments

Run specific modes manually:

```bash
# Full Fine-tuning
python train_yunmin.py --mode baseline

# LoRA-only  
python train_yunmin.py --mode lora

# Scan-only
python train_yunmin.py --mode scan

# IA3-only
python train_yunmin.py --mode ia3

# IA3 + LoRA
python train_yunmin.py --mode ia3_lora

# Hybrid (LoRA + Scan)
python train_yunmin.py --mode hybrid
```

### 3. Batch Experiments (Recommended)

Run all experiments automatically:

```bash
python run_experiments.py
```

Expected runtime: **~2-4 hours** depending on hardware.

## ğŸ“ˆ Expected Results

### Trainable Parameters

| Mode | Total Params | Trainable | Percentage |
|------|-------------|-----------|------------|
| Baseline | 161,698,304 | 161,698,304 | 100.00% |
| LoRA-only | 161,698,304 | ~2,392,064 | ~1.48% |
| Scan-only | 161,698,304 | 161,698,304 | 100.00% |
| Hybrid | 161,698,304 | ~2,392,064 | ~1.48% |
| IAÂ³-only | 161,698,304 | 161,698,304 | 100.00% |
| IAÂ³ + LoRA | 161,698,304 | ~2,392,064 | ~1.48% |

### Performance Expectations

Based on previous testing:

- **Scan-only**: ~99% perplexity reduction vs baseline
- **LoRA-only**: Efficient training with minimal parameters
- **Hybrid**: Best of both worlds - efficiency + performance

## ğŸ“ Output Files

Each experiment generates:

### Individual Results
```
results_yunmin_baseline_seed42.txt
results_yunmin_lora_seed42.txt
results_yunmin_scan_seed42.txt
results_yunmin_hybrid_seed42.txt
```

### Batch Results (from run_experiments.py)
```
batch_results/
â”œâ”€â”€ experiment_summary_YYYYMMDD_HHMMSS.json
â””â”€â”€ aggregated_metrics.json
```

### W&B Dashboard

All experiments automatically log to Weights & Biases:
- Project: `yunmin-mamba-wikitext2`
- Individual runs: `yunmin_{mode}_seed{seed}`

## âš™ï¸ Configuration Options

### Command Line Arguments

```bash
python train_yunmin.py \
  --mode {baseline,lora,scan,hybrid,ia3,ia3_lora} \
  --seed 42 \
  --epochs 3 \
  --batch_size 4 \
  --lr 5e-5 \
  --max_length 256
```

### Hardware Requirements

**Minimum:**
- GPU: 8GB VRAM (RTX 3070 or better)
- RAM: 16GB system memory
- Storage: 5GB free space

**Recommended:**
- GPU: 16GB+ VRAM (RTX 4080/A100)
- RAM: 32GB system memory
- Storage: 10GB free space

## ğŸ”§ Troubleshooting

### Common Issues

1. **CUDA Out of Memory**
   ```bash
   # Reduce batch size
   python train_yunmin.py --mode baseline --batch_size 2
   ```

2. **Tokenizer Issues**
   ```bash
   # The script automatically uses GPTNeoX tokenizer for Mamba
   # No action needed
   ```

3. **Scan Patch Fails**
   ```bash
   # Check scan_order.npy exists
   ls -la scan_order.npy scan_order_inv.npy
   
   # Regenerate if missing
   python run_correlation_scan.py
   ```

### Validation Commands

```bash
# Check model loading
python -c "from transformers import AutoModelForCausalLM; print('âœ… Model loads successfully')"

# Check scan patch
python -c "from scan_patch import apply_scan_patch; print('âœ… Scan patch imports')"

# Check LoRA setup
python -c "from peft import LoraConfig; print('âœ… PEFT imports')"
```

## ğŸ“Š Research Results Format

The experiments generate publication-ready results:

### Summary Table Format
```
| Mode     | PPL    | Time(s) | Trainable% | Memory(GB) |
|----------|--------|---------|------------|------------|
| Baseline | 156.42 | 1,234.5 | 100.00     | 12.5       |
| LoRA     | 147.23 | 987.3   | 1.48       | 8.2        |
| Scan     | 98.15  | 1,156.8 | 100.00     | 12.8       |
| Hybrid   | 89.76  | 945.2   | 1.48       | 8.4        |
| IAÂ³-only | 92.34 | 900.1  | 100.00     | 8.3        |
| IAÂ³ + LoRA | 88.50 | 820.0   | 1.48       | 7.9        |
```

### Key Performance Indicators
- **Efficiency**: Trainable parameter reduction
- **Effectiveness**: Perplexity improvement  
- **Speed**: Training time comparison
- **Memory**: GPU utilization optimization

## ğŸ¯ Next Steps

After completing experiments:

1. **Analyze W&B Results** - Compare learning curves and metrics
2. **Generate Research Plots** - Export visualizations for papers
3. **Scale Testing** - Try different model sizes (70M, 370M, 1.4B)
4. **Dataset Variation** - Test on other datasets (Penn Treebank, etc.)

## ğŸ“ Support

For issues or questions:
1. Check this guide first
2. Review the generated log files
3. Examine W&B dashboard for detailed metrics
4. Validate environment setup with `quick_test.py` 