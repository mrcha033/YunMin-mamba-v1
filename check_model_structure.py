# check_model_structure.py
from transformers import AutoModelForCausalLM
import torch

# ëª¨ë¸ ë¡œë“œ
base_model_id = "state-spaces/mamba-130m"
model = AutoModelForCausalLM.from_pretrained(
    base_model_id, 
    torch_dtype=torch.float32,
    ignore_mismatched_sizes=True
)

print("ğŸ” ëª¨ë¸ êµ¬ì¡° ë‚´ ëª¨ë“  Linear ë ˆì´ì–´ í™•ì¸:")
print("=" * 60)

linear_modules = []
for name, module in model.named_modules():
    if isinstance(module, torch.nn.Linear):
        linear_modules.append(name)
        print(f"ğŸ“ {name}")

print("\nğŸ¯ SSM ê´€ë ¨ Linear ë ˆì´ì–´ (mixer í¬í•¨):")
print("=" * 60)
ssm_modules = [name for name in linear_modules if "mixer" in name]
for name in ssm_modules:
    print(f"âœ… {name}")

print(f"\nğŸ“Š ì „ì²´ Linear ë ˆì´ì–´ ìˆ˜: {len(linear_modules)}")
print(f"ğŸ“Š SSM Linear ë ˆì´ì–´ ìˆ˜: {len(ssm_modules)}")

# target_modules ê²€ì¦
target_modules = [
    "mixer.in_proj",
    "mixer.x_proj", 
    "mixer.dt_proj",
    "mixer.out_proj"
]

print(f"\nğŸ§ª target_modules ê²€ì¦:")
print("=" * 60)
for target in target_modules:
    found = any(target in name for name in linear_modules)
    status = "âœ… FOUND" if found else "âŒ NOT FOUND"
    print(f"{status}: {target}")

print(f"\nğŸ“‹ ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì •í™•í•œ ëª¨ë“ˆëª…:")
print("=" * 60)
for target in target_modules:
    matches = [name for name in linear_modules if target.split('.')[-1] in name and "mixer" in name]
    if matches:
        for match in matches:
            print(f"ğŸ¯ {target} â†’ {match}")
    else:
        print(f"âŒ {target} â†’ NOT FOUND") 