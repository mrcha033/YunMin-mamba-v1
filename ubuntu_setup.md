# ğŸ§ Ubuntu í™˜ê²½ ì„¤ì • ê°€ì´ë“œ

Hardware-Data-Parameter Co-Design Frameworkë¥¼ Ubuntu í™˜ê²½ì—ì„œ ì‹¤í–‰í•˜ê¸° ìœ„í•œ ì™„ì „ ê°€ì´ë“œì…ë‹ˆë‹¤.

## ğŸš€ ë¹ ë¥¸ ì‹œì‘ (Dry Run)

### 1ë‹¨ê³„: ì €ì¥ì†Œ í´ë¡  ë° ì§„ì…
```bash
git clone <repository-url>
cd YunMin-mamba-v1
```

### 2ë‹¨ê³„: Dry Run ì‹¤í–‰ (ìë™ ì„¤ì •)
```bash
# ì‹¤í–‰ ê¶Œí•œ ë¶€ì—¬
chmod +x ubuntu_dry_run.sh

# Dry run ì‹¤í–‰ (ëª¨ë“  ì„¤ì • ìë™í™”)
./ubuntu_dry_run.sh
```

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ë‹¤ìŒì„ ìë™ìœ¼ë¡œ ìˆ˜í–‰í•©ë‹ˆë‹¤:
- âœ… ì‹œìŠ¤í…œ í™˜ê²½ í™•ì¸
- âœ… Python ë° ì˜ì¡´ì„± ì„¤ì¹˜
- âœ… GPU ìƒíƒœ í™•ì¸
- âœ… ê°€ìƒí™˜ê²½ ìƒì„± ë° í™œì„±í™”
- âœ… í”„ë¡œì íŠ¸ êµ¬ì¡° ê²€ì¦
- âœ… ëª¨ë¸ ì„í¬íŠ¸ í…ŒìŠ¤íŠ¸
- âœ… ì„¤ì • íŒŒì¼ ê²€ì¦
- âœ… ìµœì†Œ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬

## ğŸ“‹ ì‹œìŠ¤í…œ ìš”êµ¬ì‚¬í•­

### ìµœì†Œ ìš”êµ¬ì‚¬í•­
- **OS**: Ubuntu 18.04+ (20.04/22.04 ê¶Œì¥)
- **RAM**: 8GB ì´ìƒ
- **ì €ì¥ê³µê°„**: 10GB ì´ìƒ
- **Python**: 3.8+ (3.9+ ê¶Œì¥)

### ê¶Œì¥ ìš”êµ¬ì‚¬í•­
- **OS**: Ubuntu 22.04 LTS
- **RAM**: 32GB ì´ìƒ
- **GPU**: NVIDIA GPU (CUDA ì§€ì›)
- **CUDA**: 11.8+ ë˜ëŠ” 12.1+
- **ì €ì¥ê³µê°„**: 50GB+ (ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ìš©)

## ğŸ”§ ìˆ˜ë™ ì„¤ì • (ê³ ê¸‰ ì‚¬ìš©ììš©)

### 1. ì‹œìŠ¤í…œ íŒ¨í‚¤ì§€ ì„¤ì¹˜
```bash
# ì‹œìŠ¤í…œ ì—…ë°ì´íŠ¸
sudo apt update && sudo apt upgrade -y

# ê¸°ë³¸ ê°œë°œ ë„êµ¬
sudo apt install -y python3 python3-pip python3-venv git curl wget

# GPU ì‚¬ìš©ì‹œ (NVIDIA)
sudo apt install -y nvidia-driver-535 nvidia-cuda-toolkit
```

### 2. Python ê°€ìƒí™˜ê²½ ì„¤ì •
```bash
# ê°€ìƒí™˜ê²½ ìƒì„±
python3 -m venv venv

# ê°€ìƒí™˜ê²½ í™œì„±í™”
source venv/bin/activate

# pip ì—…ê·¸ë ˆì´ë“œ
pip install --upgrade pip
```

### 3. ì˜ì¡´ì„± ì„¤ì¹˜

#### CPU ë²„ì „ (í…ŒìŠ¤íŠ¸ìš©)
```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu
pip install transformers datasets pyyaml numpy psutil
```

#### GPU ë²„ì „ (CUDA 12.1)
```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
pip install transformers datasets pyyaml numpy psutil
```

#### ì „ì²´ ì˜ì¡´ì„± (requirements.txt ì‚¬ìš©)
```bash
pip install -r requirements.txt
```

## ğŸ¯ ì‹¤í–‰ ì˜µì…˜

### Option 1: Dry Run (ë¹ ë¥¸ í…ŒìŠ¤íŠ¸)
```bash
# ì„¤ì • í™•ì¸ ë° ìµœì†Œ í…ŒìŠ¤íŠ¸
python3 main.py --config configs/dry_run_config.yaml --mode full_pipeline --debug

# ë˜ëŠ” ê°œë³„ í…ŒìŠ¤íŠ¸
python3 train.py --config configs/dry_run_config.yaml --phase pretrain --model baseline
```

### Option 2: CPU ì‹¤í–‰ (GPU ì—†ëŠ” í™˜ê²½)
```bash
# unified_config.yamlì—ì„œ device: "cpu" ì„¤ì • í›„
python3 main.py --config configs/unified_config.yaml --mode full_pipeline
```

### Option 3: GPU ì‹¤í–‰ (í’€ ìŠ¤ì¼€ì¼)
```bash
# unified_config.yamlì—ì„œ device: "cuda" ì„¤ì • í›„
python3 main.py --config configs/unified_config.yaml --mode full_pipeline
```

## ğŸ” í™˜ê²½ ê²€ì¦

### GPU í™•ì¸
```bash
# NVIDIA GPU ìƒíƒœ í™•ì¸
nvidia-smi

# CUDA ë²„ì „ í™•ì¸
nvcc --version

# PyTorch CUDA ì§€ì› í™•ì¸
python3 -c "import torch; print(f'CUDA Available: {torch.cuda.is_available()}')"
```

### ë©”ëª¨ë¦¬ í™•ì¸
```bash
# RAM í™•ì¸
free -h

# ë””ìŠ¤í¬ í™•ì¸
df -h

# GPU ë©”ëª¨ë¦¬ í™•ì¸ (NVIDIA)
nvidia-smi --query-gpu=memory.total,memory.used,memory.free --format=csv
```

## ğŸ“Š ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§

### ê¸°ë³¸ ëª¨ë‹ˆí„°ë§
```bash
# CPU/ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§
htop

# GPU ëª¨ë‹ˆí„°ë§ (ì‹¤ì‹œê°„)
watch -n 1 nvidia-smi

# ë””ìŠ¤í¬ I/O ëª¨ë‹ˆí„°ë§
iotop
```

### ê³ ê¸‰ ëª¨ë‹ˆí„°ë§
```bash
# í”„ë¡œì„¸ìŠ¤ë³„ GPU ì‚¬ìš©ëŸ‰
nvidia-smi pmon

# ìƒì„¸ GPU ì •ë³´
nvidia-smi -l 1 --query-gpu=timestamp,name,pci.bus_id,driver_version,pstate,pcie.link.gen.max,pcie.link.gen.current,temperature.gpu,utilization.gpu,utilization.memory,memory.total,memory.free,memory.used --format=csv
```

## ğŸ› ë¬¸ì œ í•´ê²°

### ì¼ë°˜ì ì¸ ë¬¸ì œë“¤

#### 1. CUDA ê´€ë ¨ ì˜¤ë¥˜
```bash
# CUDA ë²„ì „ ë¶ˆì¼ì¹˜
pip uninstall torch torchvision torchaudio
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121

# CUDA ë¼ì´ë¸ŒëŸ¬ë¦¬ ê²½ë¡œ ë¬¸ì œ
export LD_LIBRARY_PATH=/usr/local/cuda/lib64:$LD_LIBRARY_PATH
```

#### 2. ë©”ëª¨ë¦¬ ë¶€ì¡± ì˜¤ë¥˜
```bash
# configs/unified_config.yamlì—ì„œ ë°°ì¹˜ í¬ê¸° ì¤„ì´ê¸°
micro_batch_size: 4  # 8ì—ì„œ 4ë¡œ ì¤„ì´ê¸°

# ë˜ëŠ” CPU ëª¨ë“œë¡œ ì „í™˜
device: "cpu"
```

#### 3. ì˜ì¡´ì„± ì„¤ì¹˜ ì˜¤ë¥˜
```bash
# ê°€ìƒí™˜ê²½ ì¬ìƒì„±
deactivate
rm -rf venv
python3 -m venv venv
source venv/bin/activate
pip install --upgrade pip
```

#### 4. ê¶Œí•œ ì˜¤ë¥˜
```bash
# ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ê¶Œí•œ
chmod +x ubuntu_dry_run.sh

# ë””ë ‰í† ë¦¬ ê¶Œí•œ
sudo chown -R $USER:$USER ./
```

### ë¡œê·¸ í™•ì¸
```bash
# ì‹¤í—˜ ë¡œê·¸ í™•ì¸
tail -f experiments/*/pipeline.log

# ì‹œìŠ¤í…œ ë¡œê·¸ í™•ì¸
dmesg | grep -i cuda
journalctl -u nvidia-persistenced
```

## ğŸ“ˆ ì„±ëŠ¥ ìµœì í™”

### ì‹œìŠ¤í…œ ìµœì í™”
```bash
# CPU ì„±ëŠ¥ ëª¨ë“œ ì„¤ì •
echo performance | sudo tee /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor

# GPU ì„±ëŠ¥ ëª¨ë“œ ì„¤ì •
nvidia-smi -pm 1
nvidia-smi -ac 1215,1410  # ë©”ëª¨ë¦¬,ê·¸ë˜í”½ í´ëŸ­ (GPU ëª¨ë¸ì— ë”°ë¼ ì¡°ì •)
```

### í™˜ê²½ ë³€ìˆ˜ ìµœì í™”
```bash
# ~/.bashrc ë˜ëŠ” ~/.zshrcì— ì¶”ê°€
export CUDA_VISIBLE_DEVICES=0
export TOKENIZERS_PARALLELISM=false
export OMP_NUM_THREADS=8
export MKL_NUM_THREADS=8
```

## ğŸ”„ ìë™í™” ìŠ¤í¬ë¦½íŠ¸

### ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
```bash
#!/bin/bash
# run_full_pipeline.sh

set -e

echo "ğŸš€ Starting Full Pipeline on Ubuntu"

# í™˜ê²½ í™œì„±í™”
source venv/bin/activate

# GPU í™•ì¸
if nvidia-smi > /dev/null 2>&1; then
    echo "âœ… GPU detected"
    CONFIG="configs/unified_config.yaml"
else
    echo "âš ï¸  No GPU, using CPU"
    CONFIG="configs/dry_run_config.yaml"
fi

# íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
python3 main.py --config $CONFIG --mode full_pipeline --experiment_name ubuntu_$(date +%Y%m%d_%H%M%S)

echo "âœ… Pipeline completed!"
```

### ëª¨ë‹ˆí„°ë§ ìŠ¤í¬ë¦½íŠ¸
```bash
#!/bin/bash
# monitor.sh

# í„°ë¯¸ë„ ë¶„í• í•˜ì—¬ ëª¨ë‹ˆí„°ë§
tmux new-session -d -s monitor
tmux split-window -h
tmux select-pane -t 0
tmux send-keys 'watch -n 1 nvidia-smi' C-m
tmux select-pane -t 1
tmux send-keys 'htop' C-m
tmux attach-session -t monitor
```

## ğŸ“š ì¶”ê°€ ë¦¬ì†ŒìŠ¤

### ìœ ìš©í•œ ëª…ë ¹ì–´ ëª¨ìŒ
```bash
# ëª¨ë¸ í¬ê¸° í™•ì¸
python3 -c "from models.baseline_ssm import BaselineSSM; m=BaselineSSM(768,12,50257,16,4); print(f'Parameters: {sum(p.numel() for p in m.parameters()):,}')"

# ì„¤ì • íŒŒì¼ ê²€ì¦
python3 -c "import yaml; print(yaml.safe_load(open('configs/unified_config.yaml')))"

# ì‹¤í—˜ ê²°ê³¼ ìš”ì•½
ls -la experiments/*/results.json
```

### ë””ë²„ê¹… ë„êµ¬
```bash
# Python ë””ë²„ê±° ì‚¬ìš©
python3 -m pdb main.py --config configs/dry_run_config.yaml --mode full_pipeline

# ë©”ëª¨ë¦¬ í”„ë¡œíŒŒì¼ë§
python3 -m memory_profiler main.py --config configs/dry_run_config.yaml --mode full_pipeline

# GPU ë©”ëª¨ë¦¬ í”„ë¡œíŒŒì¼ë§
python3 -c "import torch; print(torch.cuda.memory_summary())"
```

---

## ğŸ‰ ì™„ë£Œ!

Ubuntu í™˜ê²½ ì„¤ì •ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ìŒ ë‹¨ê³„ë¡œ ì§„í–‰í•˜ì„¸ìš”:

1. **Dry Run ì‹¤í–‰**: `./ubuntu_dry_run.sh`
2. **ì „ì²´ íŒŒì´í”„ë¼ì¸**: `python3 main.py --config configs/unified_config.yaml --mode full_pipeline`
3. **ê²°ê³¼ í™•ì¸**: `cat ubuntu_dry_run_report.txt`

ë¬¸ì œê°€ ë°œìƒí•˜ë©´ ìœ„ì˜ ë¬¸ì œ í•´ê²° ì„¹ì…˜ì„ ì°¸ì¡°í•˜ê±°ë‚˜ ë¡œê·¸ë¥¼ í™•ì¸í•˜ì„¸ìš”! ğŸ§âœ¨ 